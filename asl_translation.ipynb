{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83234d81-fda7-4846-81a5-f91ec9c95d76",
   "metadata": {},
   "source": [
    "# Sign Language Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb4ede2-d4bd-41c8-8209-553648a13ee2",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7d58af3-437b-4010-a47a-8eb4dad8af1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\ntry {\nrequire(['notebook/js/codecell'], function(codecell) {\n  codecell.CodeCell.options_default.highlight_modes[\n      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n      Jupyter.notebook.get_cells().map(function(cell){\n          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n  });\n});\n} catch (e) {};\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\ntry {\nrequire(['notebook/js/codecell'], function(codecell) {\n  codecell.CodeCell.options_default.highlight_modes[\n      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n      Jupyter.notebook.get_cells().map(function(cell){\n          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n  });\n});\n} catch (e) {};\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pynq_dpu import DpuOverlay\n",
    "from pynq.lib.video import *\n",
    "\n",
    "overlay = DpuOverlay(\"dpu.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473c6ed6-710d-4eec-9b2e-49c92890e945",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f479497-1cf6-496d-8198-64b6b9b1bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_W = 640\n",
    "FRAME_H = 480\n",
    "\n",
    "class_map = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f6a988-9959-4253-a01e-725dcae59a7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eaf09f-e52b-4994-896b-0bcf4a988f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_shortest_edge(image, size):\n",
    "    H, W = image.shape[:2]\n",
    "    if H >= W:\n",
    "        nW = size\n",
    "        nH = int(float(H)/W * size)\n",
    "    else:\n",
    "        nH = size\n",
    "        nW = int(float(W)/H * size)\n",
    "    return cv2.resize(image,(nW,nH))\n",
    "\n",
    "def normalize_image(image, mean = [0.519, 0.4992, 0.5139], std = [0.2283, 0.2557, 0.2639]):\n",
    "    image = image.astype(\"float32\")\n",
    "\n",
    "    B, G, R = cv2.split(image)\n",
    "\n",
    "    B = (B - mean[0]) / std[0]\n",
    "    G = (G - mean[1]) / std[1]\n",
    "    R = (R - mean[2]) / std[2]\n",
    "\n",
    "    image = cv2.merge([R, G, B])\n",
    "\n",
    "    return image\n",
    "\n",
    "def BGR2RGB(image):\n",
    "    B, G, R = cv2.split(image)\n",
    "    image = cv2.merge([R, G, B])\n",
    "    return image\n",
    "\n",
    "def central_crop(image, crop_height, crop_width):\n",
    "    image_height = image.shape[0]\n",
    "    image_width = image.shape[1]\n",
    "    offset_height = (image_height - crop_height) // 2\n",
    "    offset_width = (image_width - crop_width) // 2\n",
    "    return image[offset_height:offset_height + crop_height, offset_width:\n",
    "                 offset_width + crop_width, :]\n",
    "\n",
    "def central_resize(image, new_height, new_width):\n",
    "    return cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "def normalize(image):\n",
    "    image=image/256.0\n",
    "    image=image-0.5\n",
    "    image=image*2\n",
    "    return image\n",
    "\n",
    "def to_tensor(image):\n",
    "    return image.astype(np.float32) / 255.0  # divide by 255\n",
    "\n",
    "def preprocess_fn(image, crop_height = 200, crop_width = 200):\n",
    "    image = central_crop(image, crop_height, crop_width)\n",
    "    image = to_tensor(image)\n",
    "    image = normalize_image(image)\n",
    "    return image\n",
    "\n",
    "def calculate_softmax(data):\n",
    "    result = np.exp(data)\n",
    "    return result\n",
    "\n",
    "def predict_label(softmax):\n",
    "    with open(\"images/words.txt\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    return lines[np.argmax(softmax)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d484a9-3749-4c76-ac76-7df2ba80fbf3",
   "metadata": {},
   "source": [
    "### webcam setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a226a6-96ce-4f39-803f-3083c35bd9e8",
   "metadata": {},
   "source": [
    "load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04661c01-b5d4-48f3-8487-0c5ffe893631",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay.load_model(\"models/CNN_best_kv260.xmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc5d956-80ee-4140-a150-c18c2fc96c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capture device is open: True\n"
     ]
    }
   ],
   "source": [
    "videoIn = cv2.VideoCapture(0 + cv2.CAP_V4L2)\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_W);\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_H);\n",
    "\n",
    "\n",
    "print(\"Capture device is open: \" + str(videoIn.isOpened()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7639b2-2cc1-4565-8ad2-c7c3521e626b",
   "metadata": {},
   "source": [
    "### Display port setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c123f1ca-6531-45fe-a708-7add3e41b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayport = DisplayPort()\n",
    "\n",
    "displayport.configure(VideoMode(640, 480, 24), PIXEL_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760bb642-d8db-4802-91b8-af2dcec5d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "dpu = overlay.runner\n",
    "\n",
    "inputTensors = dpu.get_input_tensors()\n",
    "outputTensors = dpu.get_output_tensors()\n",
    "\n",
    "shapeIn = tuple(inputTensors[0].dims)\n",
    "shapeOut = tuple(outputTensors[0].dims)\n",
    "outputSize = int(outputTensors[0].get_data_size() / shapeIn[0])\n",
    "\n",
    "output_data = [np.empty(shapeOut, dtype=np.float32, order=\"C\")]\n",
    "input_data = [np.empty(shapeIn, dtype=np.float32, order=\"C\")]\n",
    "image = input_data[0]\n",
    "\n",
    "# load the logo\n",
    "logo = cv2.imread(\"./images/logo_no_text.png\", cv2.IMREAD_UNCHANGED)\n",
    "logo = cv2.resize(logo, (100, 100))\n",
    "lh, lw = logo.shape[:2]  # logo height, width\n",
    "\n",
    "# For FPS calculation\n",
    "prev_time = time.time()\n",
    "fps = 0.0\n",
    "INF_CNT_MAX = 20\n",
    "inf_cnt = INF_CNT_MAX # keep high so that inference runs on first frame and vars are initialized\n",
    "\n",
    "while True:\n",
    "    ret, frame_vga = videoIn.read()\n",
    "\n",
    "    if (ret):\n",
    "        # process for DPU \n",
    "        preprocessed = preprocess_fn(frame_vga)\n",
    "        image[0,...] = preprocessed.reshape(shapeIn[1:])\n",
    "        \n",
    "        # run inference\n",
    "        if inf_cnt < INF_CNT_MAX:\n",
    "            inf_cnt += 1\n",
    "        else:\n",
    "            inf_cnt = 0\n",
    "            job_id = dpu.execute_async(input_data, output_data)\n",
    "            dpu.wait(job_id)\n",
    "            temp = [j.reshape(1, outputSize) for j in output_data]\n",
    "            softmax = calculate_softmax(temp[0][0])\n",
    "            prediction = np.argmax(softmax)\n",
    "            class_name = class_map[np.argmax(softmax)]\n",
    "        \n",
    "        # FPS computation\n",
    "        curr_time = time.time()\n",
    "        fps = 1.0 / (curr_time - prev_time)\n",
    "        prev_time = curr_time\n",
    "        \n",
    "        # draw overlay text\n",
    "        display_frame = frame_vga.copy()\n",
    "        h, w, _ = display_frame.shape\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 2.0\n",
    "        thickness = 3\n",
    "        # Class name: top-left\n",
    "        cv2.putText(display_frame, f\"{class_name}\", (20, 60),\n",
    "                    font, font_scale, (255, 0, 0), thickness, cv2.LINE_AA)\n",
    "\n",
    "        # FPS: top-right (shifted left by ~200 px for space)\n",
    "        cv2.putText(display_frame, f\"FPS: {int(fps)}\", (w - 320, 60),\n",
    "                    font, font_scale, (0, 255, 255), thickness, cv2.LINE_AA)\n",
    "        \n",
    "        box_size = 200\n",
    "        x1 = w // 2 - box_size // 2\n",
    "        y1 = h // 2 - box_size // 2\n",
    "        x2 = x1 + box_size\n",
    "        y2 = y1 + box_size\n",
    "\n",
    "        cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 0, 255), 3)\n",
    "        \n",
    "        # print logo\n",
    "        h, w, _ = display_frame.shape\n",
    "        lx, ly = 20, h - lh - 20   # 20px margin from left and bottom\n",
    "\n",
    "        roi = display_frame[ly:ly+lh, lx:lx+lw]\n",
    "        roi[:] = logo\n",
    "\n",
    "        # send to display port\n",
    "        outframe = displayport.newframe()\n",
    "        outframe[:] = display_frame\n",
    "        displayport.writeframe(outframe)\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError(\"Error while reading from camera.\")\n",
    "\n",
    "    time.sleep(0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dcc743-9689-4eb1-bf49-d1c5e4a3d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "videoIn.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7028bd-5ec0-4cde-90e8-a7ee60b651e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
