{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83234d81-fda7-4846-81a5-f91ec9c95d76",
   "metadata": {},
   "source": [
    "# Sign Language Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb4ede2-d4bd-41c8-8209-553648a13ee2",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7d58af3-437b-4010-a47a-8eb4dad8af1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pynq_dpu import DpuOverlay\n",
    "from pynq.lib.video import *\n",
    "\n",
    "overlay = DpuOverlay(\"dpu.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473c6ed6-710d-4eec-9b2e-49c92890e945",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f479497-1cf6-496d-8198-64b6b9b1bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_W = 640\n",
    "FRAME_H = 480\n",
    "\n",
    "_R_MEAN = 123.68\n",
    "_G_MEAN = 116.78\n",
    "_B_MEAN = 103.94\n",
    "\n",
    "MEANS = [_B_MEAN,_G_MEAN,_R_MEAN]\n",
    "\n",
    "class_map = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f6a988-9959-4253-a01e-725dcae59a7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1eaf09f-e52b-4994-896b-0bcf4a988f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_shortest_edge(image, size):\n",
    "    H, W = image.shape[:2]\n",
    "    if H >= W:\n",
    "        nW = size\n",
    "        nH = int(float(H)/W * size)\n",
    "    else:\n",
    "        nH = size\n",
    "        nW = int(float(W)/H * size)\n",
    "    return cv2.resize(image,(nW,nH))\n",
    "\n",
    "def normalize_image(image, mean = [0.8969, 0.8335, 0.8416], std = [0.1565, 0.25, 0.24]):\n",
    "    # Convert to float32 for safety\n",
    "    image = image.astype(\"float32\")\n",
    "\n",
    "    # Split channels (OpenCV loads as BGR by default)\n",
    "    B, G, R = cv2.split(image)\n",
    "\n",
    "    # Normalize: (channel - mean) / std\n",
    "    B = (B - mean[0]) / std[0]\n",
    "    G = (G - mean[1]) / std[1]\n",
    "    R = (R - mean[2]) / std[2]\n",
    "\n",
    "    # Merge back (keep channel order consistent with training, usually RGB)\n",
    "    image = cv2.merge([R, G, B])\n",
    "\n",
    "    return image\n",
    "\n",
    "def BGR2RGB(image):\n",
    "    B, G, R = cv2.split(image)\n",
    "    image = cv2.merge([R, G, B])\n",
    "    return image\n",
    "\n",
    "def central_crop(image, crop_height, crop_width):\n",
    "    image_height = image.shape[0]\n",
    "    image_width = image.shape[1]\n",
    "    offset_height = (image_height - crop_height) // 2\n",
    "    offset_width = (image_width - crop_width) // 2\n",
    "    return image[offset_height:offset_height + crop_height, offset_width:\n",
    "                 offset_width + crop_width, :]\n",
    "\n",
    "def central_resize(image, new_height, new_width):\n",
    "    return cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "def normalize(image):\n",
    "    image=image/256.0\n",
    "    image=image-0.5\n",
    "    image=image*2\n",
    "    return image\n",
    "\n",
    "def to_tensor(image):\n",
    "    return image.astype(np.float32) / 255.0  # divide by 255\n",
    "\n",
    "def preprocess_fn(image, crop_height = 224, crop_width = 224):\n",
    "    # image = resize_shortest_edge(image, 256)\n",
    "    image = BGR2RGB(image)\n",
    "    image = central_resize(image, crop_height, crop_width)\n",
    "    image = to_tensor(image)\n",
    "    image = normalize_image(image)\n",
    "    # image = central_crop(image, crop_height, crop_width)\n",
    "    return image\n",
    "\n",
    "def calculate_softmax(data):\n",
    "    result = np.exp(data)\n",
    "    return result\n",
    "\n",
    "def predict_label(softmax):\n",
    "    with open(\"images/words.txt\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    return lines[np.argmax(softmax)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d484a9-3749-4c76-ac76-7df2ba80fbf3",
   "metadata": {},
   "source": [
    "### webcam setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a226a6-96ce-4f39-803f-3083c35bd9e8",
   "metadata": {},
   "source": [
    "load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04661c01-b5d4-48f3-8487-0c5ffe893631",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay.load_model(\"models/CNN_kv260.xmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc5d956-80ee-4140-a150-c18c2fc96c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capture device is open: True\n"
     ]
    }
   ],
   "source": [
    "videoIn = cv2.VideoCapture(0 + cv2.CAP_V4L2)\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_W);\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_H);\n",
    "\n",
    "\n",
    "print(\"Capture device is open: \" + str(videoIn.isOpened()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7639b2-2cc1-4565-8ad2-c7c3521e626b",
   "metadata": {},
   "source": [
    "### Display port setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c123f1ca-6531-45fe-a708-7add3e41b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayport = DisplayPort()\n",
    "\n",
    "displayport.configure(VideoMode(640, 480, 24), PIXEL_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760bb642-d8db-4802-91b8-af2dcec5d7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "dpu = overlay.runner\n",
    "\n",
    "inputTensors = dpu.get_input_tensors()\n",
    "outputTensors = dpu.get_output_tensors()\n",
    "\n",
    "shapeIn = tuple(inputTensors[0].dims)\n",
    "shapeOut = tuple(outputTensors[0].dims)\n",
    "outputSize = int(outputTensors[0].get_data_size() / shapeIn[0])\n",
    "\n",
    "output_data = [np.empty(shapeOut, dtype=np.float32, order=\"C\")]\n",
    "input_data = [np.empty(shapeIn, dtype=np.float32, order=\"C\")]\n",
    "image = input_data[0]\n",
    "\n",
    "while True:\n",
    "    #for i in range(10):\n",
    "    ret, frame_vga = videoIn.read()\n",
    "\n",
    "    if (ret):\n",
    "        outframe = displayport.newframe()\n",
    "\n",
    "        outframe[:] = frame_vga\n",
    "        displayport.writeframe(outframe)\n",
    "        # TODO: add classification\n",
    "        preprocessed = preprocess_fn(frame_vga)\n",
    "        image[0,...] = preprocessed.reshape(shapeIn[1:])\n",
    "        # p_img = preprocessed.reshape(shapeIn[1:])\n",
    "        job_id = dpu.execute_async(input_data, output_data)\n",
    "        dpu.wait(job_id)\n",
    "        temp = [j.reshape(1, outputSize) for j in output_data]\n",
    "        softmax = calculate_softmax(temp[0][0])\n",
    "        \n",
    "        prediction = np.argmax(softmax)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        print(class_map[np.argmax(softmax)])\n",
    "        #crop_img = central_resize(frame_vga, 224, 224)\n",
    "        #plt.imshow(crop_img)\n",
    "        # Show classification result on processed image\n",
    "\n",
    "        \n",
    "        #break\n",
    "        # print(\"Classification: {}\".format(class_map[np.argmax(softmax)]))\n",
    "        \n",
    "    else:\n",
    "        raise RuntimeError(\"Error while reading from camera.\")\n",
    "    time.sleep(0.05)\n",
    "#videoIn.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595bc49b-3e4a-491c-920c-61d3ed53c9b0",
   "metadata": {},
   "source": [
    "test the camera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dcc743-9689-4eb1-bf49-d1c5e4a3d5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d256c85-8e1e-46c3-91a4-8cb07eb136d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7028bd-5ec0-4cde-90e8-a7ee60b651e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
